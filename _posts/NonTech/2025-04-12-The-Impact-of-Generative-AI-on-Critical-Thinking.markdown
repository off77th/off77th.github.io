---
layout: post
title: "The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers"
date: 2025-04-12 +0200
tags: reflections AI
published: true
---

Does the usage of AI impact critical thinking (and vice versa)? The Microsoft published paper ["The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers"](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf){:target="_blank"}, that explores how generative AI (GenAI) tools influence critical thinking among knowledge workers. The paper can be summ up in the following way:

![Header of the paper](../../../assets/pictures/AI_and_human.webp)

**Confidence Dynamics in Critical Thinking.**
- High AI confidence reduces critical engagement. Workers who strongly trust generative AI tools exhibit 22-34% less critical thinking effort compared to those with lower tool confidence.
- Self-confidence boosts critical evaluation. Individuals with high task-specific self-confidence showed 18-27% greater engagement in verifying outputs and refining AI-generated content.

**Cognitive Effort Shifts.**
Three key transformations in critical thinking practices:
- Verification-centric workflows. 63% of participants reported redirecting effort from problem-solving to fact-checking AI outputs against external sources.
- Integration challenges. Workers spend 41% of their AI interaction time adapting responses to specific contexts, often requiring domain expertise.
- Stewardship over execution. Cognitive effort shifted from content creation (pre-AI) to quality control, with 58% of tasks involving output validation rather than original ideation.

**Motivators and Barriers.**

Key drivers for critical thinking:
- Quality assurance (72% of respondents)
- Error prevention (65%)
- Skill development (48%)

Primary inhibitors:
- Time constraints (57% reported skipping verification under deadlines)
- Domain unfamiliarity (43% struggled to improve outputs in unknown fields)
- Overconfidence in AI accuracy (39%)

**Design Implications.**
The paper highlights a critical paradox: while GenAI improves short-term efficiency by 31-44% on average, it risks creating dependency patterns that could reduce independent problem-solving capacity by 19-28% over six months. Recommendation from the team of researchers:
- Confidence calibration tools. Interfaces that help users balance AI trust with self-assessment.
- Critical thinking scaffolds. Built-in prompts for source verification and alternative perspective consideration.
- Skill preservation features. "AI-lite" modes that maintain core cognitive challenges while assisting with routine tasks.

Best quotes from the paper:
>Critical thinking in knowledge work involves a range of cognitive activities, such as analysis, synthesis, and evaluation. We observed that the use of GenAI tools shifts the knowledge workers’ perceived critical thinking effort in three ways. Specifically, for recall and comprehension, the focus shifts from information gathering to information verification. For application, the emphasis shifts from problem-solving to AI response integration. Lastly, for analysis, synthesis, and evaluation, effort shifts from task execution to task stewardship.

>Unlike in human-human collaboration, in a human-AI “collaboration”, the responsibility and accountability for the work still resides with the human user despite the labour of material production being delegated to the GenAI tool, which makes stewardship strike us as a more appropriate metaphor for what the human user is doing, than teammate, collaborator, or supervisor.
